{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2kcCrxQn-zQ"
   },
   "source": [
    "DATA MINING CSC440 - PROJECT\n",
    "SUBMITTED BY - SAJID HUSSAIN RAFI AHAMED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "eHaAehQEzGi_"
   },
   "outputs": [],
   "source": [
    "# import necesarry Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import *\n",
    "from itertools import *\n",
    "import time\n",
    "import math\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hgqNVqAin-za"
   },
   "outputs": [],
   "source": [
    "# Importing the UCI Adult Dataset\n",
    "columns_names=[\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education-num\",\"marital-status\",\"occupation\",\n",
    "\"relationship\",\"race\",\"sex\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\",\"salary\"]\n",
    "def data_fetch():\n",
    "        transaction = list()\n",
    "        open_text_file = open(\"adult.data.txt\", 'r')\n",
    "        transaction_counter = 0\n",
    "        for x in open_text_file:\n",
    "            transaction_counter = transaction_counter + 1\n",
    "            tran1 = x.strip().rstrip(',')\n",
    "            tran1 = tran1.split(', ')\n",
    "            transaction.append(tran1)\n",
    "        return transaction, transaction_counter\n",
    "data,data_count=data_fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zx8hShrSn-zb",
    "outputId": "ae844607-1abe-42ae-bf3c-4b26bcc5bbe4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32562"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The UCI Dataset contains 32562 data entries spanning over 15 columns\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8VxjKRLQn-zd",
    "outputId": "9027bef0-dbc2-44d8-b7d7-4fa7efcde912"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age         workclass  fnlwgt  education education-num      marital-status  \\\n",
       "0  39         State-gov   77516  Bachelors            13       Never-married   \n",
       "1  50  Self-emp-not-inc   83311  Bachelors            13  Married-civ-spouse   \n",
       "2  38           Private  215646    HS-grad             9            Divorced   \n",
       "3  53           Private  234721       11th             7  Married-civ-spouse   \n",
       "4  28           Private  338409  Bachelors            13  Married-civ-spouse   \n",
       "\n",
       "          occupation   relationship   race     sex capital-gain capital-loss  \\\n",
       "0       Adm-clerical  Not-in-family  White    Male         2174            0   \n",
       "1    Exec-managerial        Husband  White    Male            0            0   \n",
       "2  Handlers-cleaners  Not-in-family  White    Male            0            0   \n",
       "3  Handlers-cleaners        Husband  Black    Male            0            0   \n",
       "4     Prof-specialty           Wife  Black  Female            0            0   \n",
       "\n",
       "  hours-per-week native-country salary  \n",
       "0             40  United-States  <=50K  \n",
       "1             13  United-States  <=50K  \n",
       "2             40  United-States  <=50K  \n",
       "3             40  United-States  <=50K  \n",
       "4             40           Cuba  <=50K  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creation of Dataframe\n",
    "dataset=pd.DataFrame(data,columns=columns_names,index=None)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cUyQwEuIn-ze"
   },
   "outputs": [],
   "source": [
    "#Dropping rows with Null Values\n",
    "dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kRoHg8qjn-zf"
   },
   "outputs": [],
   "source": [
    "# Dropping columns with Numerical Values\n",
    "dataset.drop([\"age\",\"fnlwgt\",\"education-num\",\"capital-gain\",\"capital-loss\",\"hours-per-week\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>native-country</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          workclass  education      marital-status         occupation  \\\n",
       "0         State-gov  Bachelors       Never-married       Adm-clerical   \n",
       "1  Self-emp-not-inc  Bachelors  Married-civ-spouse    Exec-managerial   \n",
       "2           Private    HS-grad            Divorced  Handlers-cleaners   \n",
       "3           Private       11th  Married-civ-spouse  Handlers-cleaners   \n",
       "4           Private  Bachelors  Married-civ-spouse     Prof-specialty   \n",
       "\n",
       "    relationship   race     sex native-country salary  \n",
       "0  Not-in-family  White    Male  United-States  <=50K  \n",
       "1        Husband  White    Male  United-States  <=50K  \n",
       "2  Not-in-family  White    Male  United-States  <=50K  \n",
       "3        Husband  Black    Male  United-States  <=50K  \n",
       "4           Wife  Black  Female           Cuba  <=50K  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>native-country</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32561</td>\n",
       "      <td>32561</td>\n",
       "      <td>32561</td>\n",
       "      <td>32561</td>\n",
       "      <td>32561</td>\n",
       "      <td>32561</td>\n",
       "      <td>32561</td>\n",
       "      <td>32561</td>\n",
       "      <td>32561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>22696</td>\n",
       "      <td>10501</td>\n",
       "      <td>14976</td>\n",
       "      <td>4140</td>\n",
       "      <td>13193</td>\n",
       "      <td>27816</td>\n",
       "      <td>21790</td>\n",
       "      <td>29170</td>\n",
       "      <td>24720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       workclass education      marital-status      occupation relationship  \\\n",
       "count      32561     32561               32561           32561        32561   \n",
       "unique         9        16                   7              15            6   \n",
       "top      Private   HS-grad  Married-civ-spouse  Prof-specialty      Husband   \n",
       "freq       22696     10501               14976            4140        13193   \n",
       "\n",
       "         race    sex native-country salary  \n",
       "count   32561  32561          32561  32561  \n",
       "unique      5      2             42      2  \n",
       "top     White   Male  United-States  <=50K  \n",
       "freq    27816  21790          29170  24720  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<=50K', '>50K'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.salary.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "JbeFmxL-n-zh"
   },
   "outputs": [],
   "source": [
    "dataset.shape\n",
    "dataset.head()\n",
    "dataset=dataset.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWM3v3Son-zi"
   },
   "source": [
    "Apriori Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "4k14jsMhn-zk"
   },
   "outputs": [],
   "source": [
    "class Apriori():\n",
    "\n",
    "  def __init__(self,df,minimum_support):\n",
    "    self.data=df # Variable to store dataset\n",
    "    self.minimum_support=minimum_support # Initialise Minimum support \n",
    "    \n",
    "  def data_fetch(self):  \n",
    "        transaction = list() \n",
    "        dataset = self.data\n",
    "        transaction_counter = 0\n",
    "        for x in dataset: # Fetching of transactions row wise from the dataset\n",
    "            transaction_counter = transaction_counter + 1 #Counter for number of transactions\n",
    "            tran1 = list(set(x)) # Remove duplicates from transactions\n",
    "            transaction.append(tran1) \n",
    "        return transaction, transaction_counter\n",
    "\n",
    "  def one_item_counter(self, input_list):\n",
    "    one_item_set= dict() # Dictionary to store item sets\n",
    "    for j in input_list:\n",
    "      for i in j:\n",
    "        if i in one_item_set:\n",
    "          one_item_set[i]=one_item_set[i]+1 # Counter to store number of occurences of itemset \n",
    "        else:\n",
    "          one_item_set[i]=1\n",
    "    return dict(sorted(one_item_set.items(),key = lambda x:x[1],reverse=True))\n",
    "  \n",
    "  def generate_l(self,trans_dict,counter): \n",
    "      number_of_transaction = counter # Total count of transactions\n",
    "      trans_to_be_deleted= list()\n",
    "      for key, value in trans_dict.items(): # Iterate through the item set dictionary\n",
    "          if float(value/number_of_transaction)<self.minimum_support: # Remove value if less than minimum support\n",
    "              trans_to_be_deleted.append(key)\n",
    "          else:\n",
    "              continue\n",
    "      for i in trans_to_be_deleted:\n",
    "          del trans_dict[i]\n",
    "      return trans_dict\n",
    "\n",
    "  def return_superset(self,list_trans,k):\n",
    "      return list(combinations(list_trans,k))  \n",
    "\n",
    "  def candidate_itemset(self,lk,k):\n",
    "      candidate_itemset=[]\n",
    "      supersets = self.return_superset(list(lk.keys()),k) # Generation of candidate keys with K item values \n",
    "      for i in supersets:\n",
    "            candidate_itemset.append(i)\n",
    "      return candidate_itemset\n",
    "\n",
    "  def item_counter(self, input_list, candidate_itemset):\n",
    "        item_set= dict()\n",
    "        for j in input_list:\n",
    "            for i in candidate_itemset:\n",
    "                if set(i).issubset(set(j)):\n",
    "                    if i in item_set:\n",
    "                        item_set[i]=item_set[i]+1\n",
    "                    else:\n",
    "                        item_set[i]=1\n",
    "        return dict(sorted(item_set.items(),key = lambda x:x[1],reverse=True))\n",
    "\n",
    "  def frequent_itemset(self):\n",
    "        frequent_dict= dict()\n",
    "        data1,c=self.data_fetch() # Calling Data Fetch function \n",
    "        one_item=self.one_item_counter(data1) \n",
    "        lk_initial=self.generate_l(one_item,c) # Generate list of items greater than minimum support\n",
    "        frequent_dict.update(lk_initial) \n",
    "        k=2 # Initialise K \n",
    "        ck=self.candidate_itemset(lk_initial,k) # Generates Candidate Keys with K=2\n",
    "        item=self.item_counter(data1,ck)  # Counts the itemsets to generate frequent pattern\n",
    "        lk=self.generate_l(item,c)\n",
    "        frequent_dict.update(lk) # Update Dictionary \n",
    "        while(len(lk)>0): # Loops through the process for various values of K\n",
    "          k=k+1\n",
    "          ck=self.candidate_itemset(lk_initial,k) \n",
    "          item=self.item_counter(data1,ck)\n",
    "          lk=self.generate_l(item,c)\n",
    "          frequent_dict.update(lk)\n",
    "        return frequent_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "JQIWYp9xn-zm",
    "outputId": "4f2c631b-c4dd-45d0-a9c8-50d184f64678"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K': 5, 'E': 4, 'O': 3, 'Y': 3, 'M': 3, ('K', 'E'): 4, ('K', 'O'): 3, ('K', 'Y'): 3, ('K', 'M'): 3, ('E', 'O'): 3, ('K', 'E', 'O'): 3}\n",
      "--- 0.0009942054748535156 seconds ---\n"
     ]
    }
   ],
   "source": [
    "dummy_data=data=[['M','O','N','K','E','Y'],['D','O','N','K','E','Y'],\n",
    "      ['M','A','K','E'],['M','U','C','K','Y'],\n",
    "      ['C','O','O','K','I','E']]\n",
    "start_time = time.time()\n",
    "ap= Apriori(df=dummy_data,minimum_support=0.6)\n",
    "freq_dict=ap.frequent_itemset()\n",
    "print(freq_dict)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "nNL7lfTjn-zo",
    "outputId": "d1a7b3ff-ca40-4d8f-8b62-35bb90c19482"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'United-States': 29170, 'White': 27816, '<=50K': 24720, 'Private': 22696, 'Male': 21790, ('United-States', 'White'): 25621, ('United-States', '<=50K'): 21999, ('White', '<=50K'): 20699, ('United-States', 'Private'): 20135}\n",
      "--- 0.7739434242248535 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "ap= Apriori(df=dataset,minimum_support=0.6)\n",
    "freq_dict=ap.frequent_itemset()\n",
    "print(freq_dict)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "330BvIOJn-zp"
   },
   "source": [
    "Improved Apriori using Partition of transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "IDVuIbH6n-zq"
   },
   "outputs": [],
   "source": [
    "'''Apriori improvement using resampling'''\n",
    "class Resampled_Apriori():\n",
    "    \n",
    "  def __init__(self,df,minimum_support,n):\n",
    "    self.data=df\n",
    "    self.minimum_support=minimum_support\n",
    "    self.count= len(df)\n",
    "    self.n=n\n",
    "\n",
    "  def data_fetch(self):\n",
    "        transaction = list()\n",
    "        dataset = self.data\n",
    "        transaction_counter = 0\n",
    "        for x in dataset:\n",
    "            transaction_counter = transaction_counter + 1\n",
    "            tran1 = list(set(x))\n",
    "            transaction.append(tran1)\n",
    "        return transaction, transaction_counter\n",
    "  \n",
    "  def sampled_data(self,data):\n",
    "        return (sample(data,self.n))\n",
    "\n",
    "  def one_item_counter(self, input_list):\n",
    "    one_item_set= dict()\n",
    "    for j in input_list:\n",
    "      for i in list(set(j)):\n",
    "        if i in one_item_set:\n",
    "          one_item_set[i]=one_item_set[i]+1\n",
    "        else:\n",
    "          one_item_set[i]=1\n",
    "    return dict(sorted(one_item_set.items(),key = lambda x:x[1],reverse=True))\n",
    "  \n",
    "  def generate_l(self,trans_dict,counter):\n",
    "      number_of_transaction = counter\n",
    "      trans_to_be_deleted= list()\n",
    "      for key, value in trans_dict.items():\n",
    "          if float(value/number_of_transaction)<self.minimum_support:\n",
    "              trans_to_be_deleted.append(key)\n",
    "          else:\n",
    "              continue\n",
    "      for i in trans_to_be_deleted:\n",
    "          del trans_dict[i]\n",
    "      return trans_dict\n",
    "\n",
    "  def return_superset(self,list_trans,k):\n",
    "      return list(combinations(list_trans,k))\n",
    "\n",
    "  def candidate_itemset(self,lk,k):\n",
    "      candidate_itemset=[]\n",
    "      supersets = self.return_superset(list(lk.keys()),k)\n",
    "      for i in supersets:\n",
    "            candidate_itemset.append(i)\n",
    "      return candidate_itemset\n",
    "\n",
    "  def item_counter(self, input_list, candidate_itemset):\n",
    "        item_set= dict()\n",
    "        for j in input_list:\n",
    "            for i in candidate_itemset:\n",
    "                if set(i).issubset(set(j)):\n",
    "                    if i in item_set:\n",
    "                        item_set[i]=item_set[i]+1\n",
    "                    else:\n",
    "                        item_set[i]=1\n",
    "        return dict(sorted(item_set.items(),key = lambda x:x[1],reverse=True))\n",
    "  \n",
    "  def frequent_itemset(self):\n",
    "        frequent_dict= dict()\n",
    "        data1,c=self.data_fetch()\n",
    "        data1=self.sampled_data(data1)\n",
    "        c=len(data1)\n",
    "        one_item=self.one_item_counter(data1)\n",
    "        lk_initial=self.generate_l(one_item,c)\n",
    "        frequent_dict.update(lk_initial)\n",
    "        k=2\n",
    "        ck=self.candidate_itemset(lk_initial,k)\n",
    "        item=self.item_counter(data1,ck)\n",
    "        lk=self.generate_l(item,c)\n",
    "        frequent_dict.update(lk)\n",
    "        while(len(lk)>0):\n",
    "          k=k+1\n",
    "          ck=self.candidate_itemset(lk_initial,k)\n",
    "          item=self.item_counter(data1,ck)\n",
    "          lk=self.generate_l(item,c)\n",
    "          frequent_dict.update(lk)\n",
    "        return frequent_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "rqKRNcsbn-zr",
    "outputId": "696a8089-8e45-4cce-e867-809f7226955b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K': 4, 'E': 3, ('K', 'E'): 3}\n",
      "--- 0.0009968280792236328 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "ap2= Resampled_Apriori(df=dummy_data,minimum_support=0.6,n=4)\n",
    "freq_dict2=ap2.frequent_itemset()\n",
    "print(freq_dict2)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "gyqeK7KTn-zs",
    "outputId": "1b24a923-993c-44fd-e0e6-aea0fc5c74bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'United-States': 446, 'White': 425, '<=50K': 383, 'Private': 358, 'Male': 326, ('United-States', 'White'): 396, ('United-States', '<=50K'): 341, ('White', '<=50K'): 320, ('United-States', 'Private'): 319, ('White', 'Private'): 300}\n",
      "--- 0.1430070400238037 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "ap2= Resampled_Apriori(df=dataset,minimum_support=0.6,n=500)\n",
    "freq_dict2=ap2.frequent_itemset()\n",
    "print(freq_dict2)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELhK80QDn-zs"
   },
   "source": [
    "Fpgrowth Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ei1IwLvLzGjD"
   },
   "outputs": [],
   "source": [
    "class Create_Node():\n",
    "  def __init__(self,data_point=None,count=1,prev=None, next=None):\n",
    "    self.data=data_point \n",
    "    self.count=count\n",
    "    self.child={}\n",
    "    self.prev=prev\n",
    "    self.next=next\n",
    "  \n",
    "  def increase_count(self,n):\n",
    "    self.count= self.count + n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "jUlkkMmizGjE"
   },
   "outputs": [],
   "source": [
    "class Fptree():\n",
    "  def __init__(self,item_set,value_counts,minimum_support):\n",
    "    # Initialisation of itemset, Value Counter and minimum support \n",
    "    self.item_set=item_set \n",
    "    self.value_counts=value_counts\n",
    "    self.minimum_support=minimum_support\n",
    "\n",
    "  def item_counter(self):\n",
    "    item_counter= defaultdict(int) # Creation of Dictionary of integer type\n",
    "    for index,item in enumerate(self.item_set):\n",
    "      for x in list(set(item)):\n",
    "        item_counter[x]+=self.value_counts[index] # counting frequency \n",
    "    return item_counter\n",
    "\n",
    "  def create_header_table(self):\n",
    "        header_table= self.item_counter()   # Creation of header table\n",
    "        header_table= self.remove_infrequent_items(header_table)\n",
    "        return header_table\n",
    "\n",
    "  def remove_infrequent_items(self,transaction_dict):\n",
    "      number_of_transaction =len(transaction_dict)\n",
    "      # Loop through the transactions and delete items below minimum support\n",
    "      trans_to_be_deleted = [key for key, value in transaction_dict.items() if value<self.minimum_support]\n",
    "      for i in trans_to_be_deleted:\n",
    "          del transaction_dict[i]\n",
    "      return {item:sup for item,sup in sorted(transaction_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "  def construct_fptree(self):\n",
    "     header_table=self.create_header_table()\n",
    "     if len(header_table)==0: \n",
    "       return None, None\n",
    "     header_table= {i:[header_table[i], None] for i in header_table}\n",
    "     fp_tree = Create_Node(data_point='Null') # Initialise NULL head node \n",
    "     for i, x in enumerate(self.item_set):\n",
    "       # Update FP Tree for each cleaned and sorted Item set \n",
    "        transaction=[]\n",
    "        for item in x:\n",
    "          if item in header_table:\n",
    "            transaction.append(item)\n",
    "        transaction.sort(key = lambda m: header_table[m][0], reverse=True)\n",
    "        current_node = fp_tree\n",
    "        for item in transaction:\n",
    "          # Update tree with the given item by traversing from root to leaf\n",
    "            current_node = self.update_fptree(item, current_node, header_table, self.value_counts[i])\n",
    "     return fp_tree, header_table\n",
    "\n",
    "  def update_fptree(self, item, node, header_table, child_count):\n",
    "    if item in node.child:\n",
    "       # If item already exists, increment the count\n",
    "        node.child[item].increase_count(child_count)\n",
    "    else:\n",
    "      # Create a new branch for the item \n",
    "        newnode = Create_Node(data_point=item,count=child_count,prev=node)\n",
    "        node.child[item] = newnode\n",
    "        # Link the branch to the header table\n",
    "        self.update_header_table(item, newnode, header_table)\n",
    "    return node.child[item]\n",
    "    \n",
    "  def update_header_table(self,item, node, header_table):\n",
    "    if header_table[item][1] is None:\n",
    "        header_table[item][1] = node\n",
    "    else:\n",
    "        left_node = header_table[item][1]\n",
    "        # Traverse to the last node then link it to the target\n",
    "        while left_node.next is not None:\n",
    "            left_node = left_node.next\n",
    "        left_node.next = node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "-e4am28BzGjF"
   },
   "outputs": [],
   "source": [
    "class Mine_Fptree():\n",
    "        def __init__(self,header_table,minimum_support,prefix, frequent_item_sets ):\n",
    "          self.header_table=header_table\n",
    "          self.minimum_support=minimum_support\n",
    "          self.prefix=prefix\n",
    "          self.frequent_item_sets= frequent_item_sets\n",
    "\n",
    "        def mine_tree(self,header_table,prefix,frequent_item_sets):\n",
    "            #Create a list with Sorted items with frequency \n",
    "            sorted_List = [k for k, v in sorted(header_table.items(), key=lambda item: item[1][0])]\n",
    "            for item in sorted_List:\n",
    "              # Keep adding suffix patterns with frequent patterns generated from conditional FP-tree\n",
    "                new_freq_itemset = prefix.copy()\n",
    "                new_freq_itemset.add(item)\n",
    "                frequent_item_sets.append(new_freq_itemset)\n",
    "                 # Find all prefix path, construct conditional pattern base\n",
    "                conditional_pattern, frequencies = self.find_all_prefixpaths(item,header_table)\n",
    "                new_Fptree=Fptree(conditional_pattern, frequencies, self.minimum_support)\n",
    "                # Construct conditonal FP Tree with conditional pattern base\n",
    "                conditional_fp_tree, new_fptable = new_Fptree.construct_fptree()\n",
    "                if new_fptable != None:\n",
    "                  #Keep mining recursively on the tree\n",
    "                    self.mine_tree(new_fptable, new_freq_itemset, frequent_item_sets)\n",
    "                    \n",
    "        def find_all_prefixpaths(self,item, header_table):\n",
    "            current_node = header_table[item][1] # Initial node in the linked list\n",
    "            conditional_pattern = []\n",
    "            frequencies = []\n",
    "            while current_node != None:\n",
    "                prefixpath = []\n",
    "                # Traverse from leaf upto the root\n",
    "                self.ascend_fptree(current_node, prefixpath)\n",
    "                if len(prefixpath) > 1:\n",
    "                    conditional_pattern.append(prefixpath[1:]) # to store prefix path \n",
    "                    frequencies.append(current_node.count) # to store count of prefix path\n",
    "                current_node = current_node.next #point to next node\n",
    "            return conditional_pattern, frequencies\n",
    "                    \n",
    "        def ascend_fptree(self,node, prefixpath):\n",
    "            if node.prev != None:\n",
    "                prefixpath.append(node.data)\n",
    "                self.ascend_fptree(node.prev, prefixpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "dMj5tQZozGjG"
   },
   "outputs": [],
   "source": [
    "minimum_support = 0.6*len(dummy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "1w5jzqwlzGjH",
    "outputId": "3a06144a-90df-4631-ef7f-c51b60ccd564"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'O'}, {'O', 'K'}, {'E', 'O', 'K'}, {'E', 'O'}, {'Y'}, {'K', 'Y'}, {'M'}, {'M', 'K'}, {'E'}, {'E', 'K'}, {'K'}]\n",
      "--- 0.0009963512420654297 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "FP= Fptree(dummy_data,[1]*len(dummy_data),minimum_support)\n",
    "fptree, header_table = FP.construct_fptree()\n",
    "freq_items_in_transaction = []\n",
    "Mining= Mine_Fptree(header_table, minimum_support, set(), freq_items_in_transaction )\n",
    "Mining.mine_tree(header_table, set(),freq_items_in_transaction)\n",
    "print(freq_items_in_transaction)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "jlBnhEg-n-zw"
   },
   "outputs": [],
   "source": [
    "minimum_support = 0.6*len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "lZq5Bzm6n-zy",
    "outputId": "64b52ecb-2d70-4af5-ff50-d3f154368c4f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Male'}, {'Private'}, {'Private', 'United-States'}, {'<=50K'}, {'<=50K', 'White'}, {'<=50K', 'United-States'}, {'White'}, {'United-States', 'White'}, {'United-States'}]\n",
      "--- 0.24140548706054688 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "FP= Fptree(dataset,[1]*len(dataset),minimum_support)\n",
    "fptree, header_table = FP.construct_fptree()\n",
    "freq_items_in_transaction = []\n",
    "Mining= Mine_Fptree(header_table, minimum_support, set(), freq_items_in_transaction )\n",
    "Mining.mine_tree(header_table, set(),freq_items_in_transaction)\n",
    "print(freq_items_in_transaction)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "sPOr-DIYn-zz"
   },
   "outputs": [],
   "source": [
    "time_taken=[]\n",
    "min_sup= np.linspace(0.2, 1.0, num=5)\n",
    "for i in min_sup:\n",
    "    start_time = time.time()\n",
    "    ap= Apriori(df=dataset,minimum_support=i)\n",
    "    freq_dict=ap.frequent_itemset()\n",
    "    time_taken.append((time.time() - start_time))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "k2rev8lbn-z0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Some-college'}, {'>50K'}, {'Not-in-family'}, {'HS-grad'}, {'Never-married'}, {'Female'}, {'Husband'}, {'Married-civ-spouse'}, {'Male'}, {'Private'}, {'Private', 'United-States'}, {'<=50K'}, {'<=50K', 'White'}, {'<=50K', 'United-States'}, {'White'}, {'United-States', 'White'}, {'United-States'}]\n"
     ]
    }
   ],
   "source": [
    "time_taken2=[]\n",
    "\n",
    "start_time = time.time()\n",
    "FP= Fptree(dataset,[1]*len(dataset),0.2*len(dataset))\n",
    "fptree, header_table = FP.construct_fptree()\n",
    "freq_items_in_transaction = []\n",
    "Mining= Mine_Fptree(header_table, minimum_support, set(), freq_items_in_transaction )\n",
    "Mining.mine_tree(header_table, set(),freq_items_in_transaction)\n",
    "print(freq_items_in_transaction)\n",
    "time_taken2.append((time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Husband'}, {'Married-civ-spouse'}, {'Male'}, {'Private'}, {'Private', 'United-States'}, {'<=50K'}, {'<=50K', 'White'}, {'<=50K', 'United-States'}, {'White'}, {'United-States', 'White'}, {'United-States'}]\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "FP= Fptree(dataset,[1]*len(dataset),0.4*len(dataset))\n",
    "fptree, header_table = FP.construct_fptree()\n",
    "freq_items_in_transaction = []\n",
    "Mining= Mine_Fptree(header_table, minimum_support, set(), freq_items_in_transaction )\n",
    "Mining.mine_tree(header_table, set(),freq_items_in_transaction)\n",
    "print(freq_items_in_transaction)\n",
    "time_taken2.append((time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Male'}, {'Private'}, {'Private', 'United-States'}, {'<=50K'}, {'<=50K', 'White'}, {'<=50K', 'United-States'}, {'White'}, {'United-States', 'White'}, {'United-States'}]\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "FP= Fptree(dataset,[1]*len(dataset),0.6*len(dataset))\n",
    "fptree, header_table = FP.construct_fptree()\n",
    "freq_items_in_transaction = []\n",
    "Mining= Mine_Fptree(header_table, minimum_support, set(), freq_items_in_transaction )\n",
    "Mining.mine_tree(header_table, set(),freq_items_in_transaction)\n",
    "print(freq_items_in_transaction)\n",
    "time_taken2.append((time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'White'}, {'United-States', 'White'}, {'United-States'}]\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "FP= Fptree(dataset,[1]*len(dataset),0.8*len(dataset))\n",
    "fptree, header_table = FP.construct_fptree()\n",
    "freq_items_in_transaction = []\n",
    "Mining= Mine_Fptree(header_table, minimum_support, set(), freq_items_in_transaction )\n",
    "Mining.mine_tree(header_table, set(),freq_items_in_transaction)\n",
    "print(freq_items_in_transaction)\n",
    "time_taken2.append((time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "vV8wwmSWn-z0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[150.9249587059021,\n",
       " 3.0856943130493164,\n",
       " 0.707111120223999,\n",
       " 0.17855381965637207,\n",
       " 0.15056347846984863]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5565123558044434,\n",
       " 0.3131685256958008,\n",
       " 0.2991957664489746,\n",
       " 0.24335074424743652]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_taken2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2, 0.4, 0.6, 0.8, 1. ])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_sup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DATA_MINING_PROJECT_IMPLEMENTATION.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
